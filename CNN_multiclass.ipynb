{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daV0Uhu1ZnFW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t37dg9UYfn-C"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "from sklearn.metrics import accuracy_score\n",
        "import random\n",
        "import statistics\n",
        "import skimage.io\n",
        "import skimage.color\n",
        "from numpy import unravel_index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsfBJv4Df_r_"
      },
      "outputs": [],
      "source": [
        "def transform(x):\n",
        "  x=(x-np.mean(x,axis=0))/np.std(x,axis=0)\n",
        "  #print(x.shape)\n",
        "  return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_6hNxJPgAIo"
      },
      "outputs": [],
      "source": [
        "# X, y = make_classification(n_samples=50000, n_features=20, n_informative=10, n_redundant=5,\n",
        "#                            n_classes=2, weights=[0.7], class_sep=0.6, random_state=15)\n",
        "b = np.load('/content/drive/MyDrive/bloodmnist.npz')\n",
        "train_images=b['train_images']\n",
        "val_images=b['val_images']\n",
        "test_images=b['test_images']\n",
        "Y_train=b['train_labels']\n",
        "Y_test=b['val_labels']\n",
        "Y_val=b['test_labels']\n",
        "train_image=[]\n",
        "test_image=[]\n",
        "val_image=[]\n",
        "for i in range(len(train_images)):\n",
        "  train_image.append(skimage.color.rgb2gray(train_images[i]))\n",
        "for i in range(len(test_images)):\n",
        "  test_image.append(skimage.color.rgb2gray(test_images[i]))\n",
        "for i in range(len(val_images)):\n",
        "  val_image.append(skimage.color.rgb2gray(val_images[i]))\n",
        "train_image=np.array(train_image)\n",
        "test_image=np.array(test_image)\n",
        "val_image=np.array(val_image)\n",
        "X_train= train_image\n",
        "X_val= test_image\n",
        "X_test= val_image\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bl8pcpYaquJj",
        "outputId": "02f0719b-4f34-4bfc-9157-fc7d2731a2ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[7]\n"
          ]
        }
      ],
      "source": [
        "print(max(Y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgsXtTl_gdGs"
      },
      "outputs": [],
      "source": [
        "def convolution(w,I,size):\n",
        "  m,n=I.shape\n",
        "  k1=size\n",
        "  I1=np.zeros((m+k1-1,n+k1-1))\n",
        "  k1=k1//2\n",
        "  I1[k1:m+k1,k1:n+k1]=I\n",
        "  I=I1.copy()\n",
        "  I1=np.zeros((m+size-1,n+size-1))\n",
        "  for i in range(k1,m+k1):\n",
        "    for j in range(k1,n+k1):\n",
        "      p=I[i-k1:i+k1+1,j-k1:j+k1+1]\n",
        "      #print(i,j,k1)\n",
        "      I1[i][j]=np.sum(np.sum(p*w))\n",
        "  return I1[1:m+1,1:n+1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpLoB-CZk2kt"
      },
      "outputs": [],
      "source": [
        "def convolution_backprop(w,I,size):\n",
        "  m,n=I.shape\n",
        "  k1=size\n",
        "  I1=np.zeros((m+k1-1,n+k1-1))\n",
        "  k1=k1//2\n",
        "  I1[k1:m+k1,k1:n+k1]=I\n",
        "  I=I1.copy()\n",
        "  m=m+size-1\n",
        "  n=n+size-1\n",
        "  k1=w.shape[0]\n",
        "  w1=np.zeros((size,size))\n",
        "  for i in range(0,size):\n",
        "    for j in range(0,size):\n",
        "      p=I[i:i+k1,j:j+k1]\n",
        "      w1[i][j]=np.sum(np.sum(p*w))\n",
        "  return w1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZT19YRUVV75p"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "  if z < 0:\n",
        "    return 1 - 1/(1 + math.exp(z))\n",
        "  else:\n",
        "    return 1/(1 + math.exp(-z))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DK-Yfa1KV95W"
      },
      "outputs": [],
      "source": [
        "def grad_sigmoid(z):\n",
        "  return sigmoid(z)*(1-sigmoid(z))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IxnX2GmI1Ji"
      },
      "outputs": [],
      "source": [
        "def getindices(F,size,stride): # reprersent stride in maxpooling\n",
        "  indexes=[]\n",
        "  relu_outputs=[]\n",
        "  for c in range(len(F)):\n",
        "    img=np.zeros(F[c].shape)\n",
        "    m,n=img.shape\n",
        "    for i in range(0,m,stride):\n",
        "      for j in range(0,n,stride):\n",
        "        p=F[c][i:i+size,j:j+size]\n",
        "        indices=unravel_index(p.argmax(), p.shape)\n",
        "        # print(indices,int(indices[0]),int(indices[1]),i,j,img.shape)\n",
        "        # if(len(indices)>2):\n",
        "        #   indices=indices[0]\n",
        "        # print(indices,len(indices))\n",
        "        img[i+int(indices[0])][j+int(indices[1])]=1\n",
        "        relu_outputs.append(max(0,p.max())) # relu is implemented at once \n",
        "    indexes.append(img)\n",
        "  relu_outputs.append(1)\n",
        "  return indexes,np.array(relu_outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SenBsRffP4hI"
      },
      "outputs": [],
      "source": [
        "# def softmax(l):\n",
        "#   k=np.exp(l)\n",
        "#   return k/np.sum(k)\n",
        "def softmax(x):\n",
        "    f = np.exp(x - np.max(x))  # shift values\n",
        "    return f / f.sum(axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQ1pXQKySgWC"
      },
      "outputs": [],
      "source": [
        "def onehotencoding(a,max1):\n",
        "  z=np.zeros(max1+1)\n",
        "  z[a]=1\n",
        "  return z "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEFFzt1oHu7a"
      },
      "outputs": [],
      "source": [
        "def forward_prop(kernel_Weights,img,size,stride,w):\n",
        "  F=[]\n",
        "  for i in range(len(kernel_Weights)):\n",
        "    F.append(convolution(kernel_Weights[i],img,size))\n",
        "  maxpool_indices,relu_outputs=getindices(F,size,stride)\n",
        "  n=len(relu_outputs)\n",
        "  # w=np.random.randn((n+1,2))\n",
        "  L=softmax(np.dot(w.T,relu_outputs))\n",
        "  # for i in range(len(L)):\n",
        "  #   L[i]=softmax(L[i])\n",
        "\n",
        "  return F,maxpool_indices,L,relu_outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1CSHecVSX5g"
      },
      "outputs": [],
      "source": [
        "def backward_prop(I,F,maxpool_indices,kernel_weights,w_lastlayer,L,relu_outputs,stride,size,Y):\n",
        "  w_new=w_lastlayer.copy()\n",
        "  l=L\n",
        "  l1=relu_outputs\n",
        "  W=w_lastlayer\n",
        "  # k=(l-Y)*l*(1-l) # error at Last layer\n",
        "  k=l-Y\n",
        "  # print(k.shape)\n",
        "  delta=k\n",
        "  dj_w=np.zeros_like(W)\n",
        "  m=len(W)\n",
        "  n=len(k)\n",
        "  # for i in range(0,m):\n",
        "  #   for j in range(0,n):\n",
        "  #     dj_w[i][j]=k[j]*l1[i]\n",
        "  l1_n=np.reshape(l1,(m,1))\n",
        "  k_n=np.reshape(k,(n,1))\n",
        "  dj_w=np.dot(l1_n,k_n.T)+W #l2 Regularizer\n",
        "\n",
        "  # for i in range(0,m):\n",
        "  #   dj_w[i]=k*l1[i]\n",
        "  lambda1=0.001\n",
        "  W=W-(lambda1*dj_w)\n",
        "  w_new=W\n",
        "  error_relu_nodes=[0]*len(relu_outputs) # error at relu output nodes\n",
        "  for i in range(len(relu_outputs)):\n",
        "    a=0\n",
        "    # for j in range(len(k)):\n",
        "    #   a+=k[j]*w_lastlayer[i][j]\n",
        "    a=max(0,np.sum(k*w_lastlayer[i]))\n",
        "    # print(k,w_lastlayer[i])\n",
        "    # if math.isnan(a) or int(a)<=0:\n",
        "    #   a=0\n",
        "    error_relu_nodes[i]=a\n",
        "  # now we need to find error of maxpool layer\n",
        "  error_maxpool=maxpool_indices.copy()\n",
        "  m1,n1=F[0].shape # size of image\n",
        "  nodes_per_image=(m1//stride)*(n1//stride)\n",
        "  for i in range(len(F)):\n",
        "    nodes=error_relu_nodes[nodes_per_image*i:nodes_per_image*(i+1)]\n",
        "    a=0\n",
        "    for j in range(0,m1,stride):\n",
        "      for y in range(0,n1,stride):\n",
        "        error_maxpool[i][j:j+size,y:y+size]=nodes[a]*error_maxpool[i][j:j+size,y:y+size]\n",
        "        a+=1\n",
        "  # till now we calculated dj/dm  m= maxpool layer\n",
        "  kernel_errors=[]\n",
        "  for i in range(len(F)):\n",
        "    X=error_maxpool[i]\n",
        "    kernel_error=convolution_backprop(X,I,size)\n",
        "    kernel_errors.append(kernel_error)\n",
        "    kernel_weights[i]=kernel_weights[i]-(0.001)*(kernel_error)\n",
        "  return kernel_weights,w_new\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cOhiP_V_Sbwg"
      },
      "outputs": [],
      "source": [
        "kernel_weights=[]\n",
        "epochs=3\n",
        "stride=2\n",
        "size=5\n",
        "filters=8\n",
        "#img_size=28*28\n",
        "max_classes=int(max(Y_train))\n",
        "n=(28//stride)*(28//stride)*filters+1\n",
        "w_lastlayer=np.random.randn(n,max_classes)\n",
        "for i in range(filters):\n",
        "  kernel_weights.append(np.random.randn(size,size))\n",
        "\n",
        "for i in range(epochs):\n",
        "  for j in range(len(X_train)):\n",
        "    Y = onehotencoding(Y_train[j],max_classes)\n",
        "    F,maxpool_indices,L,relu_outputs= forward_prop(kernel_weights,X_train[i],size,stride,w_lastlayer)\n",
        "    k_weights,w_new = backward_prop(X_train[i],F,maxpool_indices,kernel_weights,w_lastlayer,L,relu_outputs,stride,size,Y_train[j])\n",
        "    kernel_weights=k_weights.copy()\n",
        "    w_lastlayer=w_new\n",
        "    # print(j,i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KTDVt4dx4R_T"
      },
      "outputs": [],
      "source": [
        "def accuracy(y_test,y_pred):\n",
        "  count =0\n",
        "  for i in range(len(y_pred)):\n",
        "    if y_pred[i]==y_test[i]:\n",
        "      count+=1\n",
        "  accuracy = count*100/len(y_pred)\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "a-px-Wn_4TzT"
      },
      "outputs": [],
      "source": [
        "def predict(kernel_weights,x,size,stride,w_lastlayer):\n",
        "  F,maxpool_indices,y,relu_outputs=forward_prop(kernel_weights,x,size,stride,w_lastlayer)\n",
        "  return np.argmax(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RgrMIWYb4VwX"
      },
      "outputs": [],
      "source": [
        "y_pred=[]\n",
        "for i in range(len(X_test)):\n",
        "  y_pred.append(predict(kernel_weights,X_test[i],size,stride,w_lastlayer)) #kernel_weights,X_train[i],size,stride,w_lastlayer\n",
        "acc=accuracy(Y_test,y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zpDKpd7E4YkM",
        "outputId": "3734578c-cc9f-4a5d-d4e4-777211405b16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.126168224299065\n"
          ]
        }
      ],
      "source": [
        "print(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9yWplYF4YaN"
      },
      "outputs": [],
      "source": [
        "y_pred=[]\n",
        "for i in range(len(X_val)):\n",
        "  y_pred.append(predict(kernel_weights,X_val[i],size,stride,w_lastlayer))\n",
        "acc=accuracy(Y_val,y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPfC3-rk4YI2"
      },
      "outputs": [],
      "source": [
        "print(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1hnYh6u4d-r"
      },
      "outputs": [],
      "source": [
        "y_pred=[]\n",
        "for i in range(len(X_train)):\n",
        "  y_pred.append(predict(kernel_weights,X_train[i],size,stride,w_lastlayer))\n",
        "acc=accuracy(Y_train,y_pred)\n",
        "print(acc)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}